---
phase: 58-audio-language
plan: 01
type: execute
---

<objective>
Implement the PRONOUNCE step type for LessonRunner, enabling pronunciation practice with TTS playback.

Purpose: Complete the missing step type so lessons can include pronunciation exercises with audio playback and optional self-recording.
Output: Working Pronounce step component with TTS fallback for Macedonian text.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior discovery (phase 54)
@.planning/phases/54-exercise-architecture-research/DISCOVERY.md

# Type definitions (already complete)
@lib/lesson-runner/types.ts

# Validation (already handles PRONOUNCE)
@lib/lesson-runner/validation.ts

# Answer handling (already handles PRONOUNCE)
@lib/lesson-runner/useLessonRunner.ts

# Component to wire into
@components/lesson/LessonRunner.tsx

# Example step components (pattern reference)
@components/lesson/steps/MultipleChoice.tsx
@components/lesson/steps/Info.tsx

# i18n files to update
@messages/en.json
@messages/mk.json

**Established patterns:**
- Step components receive `step`, `onAnswer`, `feedback`, `disabled` props
- Use StepComponentProps<T> generic for typing
- Card styling: `rounded-[var(--radius-card)] border border-border/50 bg-card/80 p-6 shadow-sm`
- Icons from lucide-react (Volume2, Play, Mic, etc.)
- WCAG touch targets: 48px minimum (h-12 w-12)

**Key context:**
- Browser Speech Synthesis API supports Macedonian (mk-MK) on most platforms
- PronounceStep already defined with: text, audioUrl?, locale, allowRecording?, allowSkip?, instructions?, phonetic?
- Answer type: `{ type: 'PRONOUNCE'; recordingBlob?: Blob; skipped: boolean }`
- useLessonRunner validates PRONOUNCE as self-assessment (always positive feedback)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TTS wrapper for Macedonian</name>
  <files>lib/tts/macedonian-tts.ts</files>
  <action>
Create a browser TTS utility wrapping the Web Speech Synthesis API:

```typescript
// lib/tts/macedonian-tts.ts

/**
 * Browser-based TTS for Macedonian text
 * Falls back to default voice if Macedonian not available
 */

export interface TTSOptions {
  rate?: number;     // 0.1 to 10, default 0.9 (slightly slower for learners)
  pitch?: number;    // 0 to 2, default 1
  volume?: number;   // 0 to 1, default 1
}

// Check if TTS is supported
export function isTTSSupported(): boolean

// Get available Macedonian voice (or best fallback)
export function getMacedonianVoice(): SpeechSynthesisVoice | null

// Speak text with promise-based API
export function speak(text: string, locale: 'mk' | 'en', options?: TTSOptions): Promise<void>

// Stop any current speech
export function stopSpeaking(): void
```

**Implementation notes:**
- Use `window.speechSynthesis` API
- Prefer voices with lang starting with 'mk' for Macedonian
- If no Macedonian voice, log warning and use default voice
- Return promise that resolves on 'end' event, rejects on 'error'
- Handle the common Safari bug where voices aren't available immediately (add retry with timeout)
- Do NOT use async/await in the speak function body - use promise constructor for event handling
  </action>
  <verify>Create a simple test: `console.log(isTTSSupported(), getMacedonianVoice()?.name)` in browser devtools</verify>
  <done>TTS wrapper exports isTTSSupported, getMacedonianVoice, speak, stopSpeaking functions</done>
</task>

<task type="auto">
  <name>Task 2: Create Pronounce step component</name>
  <files>components/lesson/steps/Pronounce.tsx</files>
  <action>
Create the Pronounce step component following the established pattern:

```typescript
// components/lesson/steps/Pronounce.tsx
'use client';

import { useState, useRef } from 'react';
import { Volume2, Play, Mic, MicOff, Loader2 } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { speak, stopSpeaking, isTTSSupported } from '@/lib/tts/macedonian-tts';
import type { PronounceStep, StepComponentProps } from '@/lib/lesson-runner/types';
```

**UI Structure:**
1. Instruction card with text to pronounce
2. Audio controls:
   - Play button (uses TTS if no audioUrl, or Audio element if audioUrl provided)
   - Phonetic hint (if provided)
3. Recording controls (if allowRecording):
   - Record/Stop button using MediaRecorder API
   - Playback of recording
4. Continue/Skip buttons

**State:**
- isPlaying: boolean (TTS or audio playing)
- isRecording: boolean
- recordedBlob: Blob | null
- hasPlayed: boolean (track if user listened at least once)

**Behavior:**
- User MUST listen at least once before continuing (unless allowSkip)
- Recording is optional - user can skip after listening
- When user taps Continue: call onAnswer({ type: 'PRONOUNCE', recordingBlob, skipped: false })
- When user taps Skip: call onAnswer({ type: 'PRONOUNCE', skipped: true })

**Styling:**
- Match existing step card styling
- Play button: prominent, 48px touch target
- Record button: red accent when recording
- Use animations for recording pulse (animate-pulse)

**Edge cases:**
- If TTS not supported and no audioUrl: show message "Audio not available on this browser"
- If MediaRecorder not supported: hide recording controls (show listen-only mode)
- Stop TTS/audio when component unmounts

**Do NOT:**
- Don't create complex audio visualization (keep simple)
- Don't persist recordings across sessions
- Don't require recording for completion
  </action>
  <verify>Import component in a test page and render with sample PronounceStep data</verify>
  <done>Pronounce.tsx component renders text, plays audio via TTS, supports optional recording</done>
</task>

<task type="auto">
  <name>Task 3: Wire Pronounce into LessonRunner</name>
  <files>components/lesson/LessonRunner.tsx, messages/en.json, messages/mk.json</files>
  <action>
**1. Add import in LessonRunner.tsx:**
```typescript
import { Pronounce } from './steps/Pronounce';
```

**2. Add case in renderStep() switch statement** (around line 200, after TAP_WORDS case):
```typescript
case 'PRONOUNCE':
  return <Pronounce step={currentStep} {...baseProps} />;
```

**3. Add i18n messages in en.json** under a new "pronounce" namespace:
```json
"pronounce": {
  "instruction": "Listen and practice saying this phrase",
  "listenFirst": "Listen at least once before continuing",
  "tapToListen": "Tap to listen",
  "tapToRecord": "Tap to record yourself",
  "recording": "Recording...",
  "playRecording": "Play your recording",
  "audioNotSupported": "Audio playback is not available on this browser",
  "recordingNotSupported": "Recording is not available on this browser"
}
```

**4. Add matching Macedonian translations in mk.json:**
```json
"pronounce": {
  "instruction": "Слушај и вежбај да го кажеш овој израз",
  "listenFirst": "Слушни барем еднаш пред да продолжиш",
  "tapToListen": "Допри за да слушнеш",
  "tapToRecord": "Допри за да се снимиш",
  "recording": "Снимање...",
  "playRecording": "Пушти ја твојата снимка",
  "audioNotSupported": "Аудио репродукцијата не е достапна на овој прелистувач",
  "recordingNotSupported": "Снимањето не е достапно на овој прелистувач"
}
```
  </action>
  <verify>npm run type-check && npm run lint</verify>
  <done>LessonRunner renders PRONOUNCE steps, i18n messages available in both locales</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `npm run type-check` passes without errors
- [ ] `npm run lint` passes without errors
- [ ] `npm run build` succeeds
- [ ] TTS plays Macedonian text in Chrome/Safari
- [ ] PRONOUNCE step renders correctly in LessonRunner
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- PRONOUNCE step type is fully functional
- TTS fallback works when no audioUrl provided
- i18n messages available in en.json and mk.json
- Component follows existing step component patterns
</success_criteria>

<output>
After completion, create `.planning/phases/58-audio-language/58-01-SUMMARY.md`
</output>
